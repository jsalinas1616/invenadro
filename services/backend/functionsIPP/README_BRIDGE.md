# ğŸŒ‰ Lambda Bridge: IPP â†’ Factor de Redondeo

## ğŸ“Š Diagrama de Flujo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 1: Frontend â†’ IPP Verificador/Iniciador                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Usuario ingresa mostradores en frontend                     â”‚
â”‚ 2. ipp-verificador valida contra Databricks                    â”‚
â”‚ 3. ipp-iniciador dispara Databricks Job 1                      â”‚
â”‚ 4. Frontend hace polling de status                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 2: Databricks Job 1 Procesa y Guarda en S3                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Databricks Job 1 recibe parÃ¡metros (job_id, mostradores)    â”‚
â”‚ 2. Procesa IPP Tradicional + Normalizador                      â”‚
â”‚ 3. Calcula Factor_A, Factor_B, Factor_C, Factor_4, etc.        â”‚
â”‚ 4. Guarda PARTICIONADO por cliente en S3:                      â”‚
â”‚    â”œâ”€â”€ resultados/{job_id}/clientes/cliente_7051602.json       â”‚
â”‚    â”œâ”€â”€ resultados/{job_id}/clientes/cliente_7051603.json       â”‚
â”‚    â””â”€â”€ resultados/{job_id}/metadata.json â† TRIGGER              â”‚
â”‚ 5. Actualiza DynamoDB: status = 'completed'                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 3: S3 Event Dispara Lambda Bridge (NUEVA) â­               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. S3 Event detecta: metadata.json creado                      â”‚
â”‚ 2. ipp-to-factor-bridge se ejecuta automÃ¡ticamente             â”‚
â”‚ 3. Lee metadata.json (obtiene lista de clientes)               â”‚
â”‚ 4. Por cada cliente:                                           â”‚
â”‚    a. Lee cliente_{id}.json desde S3                           â”‚
â”‚    b. Transforma JSON â†’ Excel (formato Factor Redondeo)        â”‚
â”‚    c. Sube Excel a uploads/ipp-to-factor/{job_id}/{cliente}/   â”‚
â”‚    d. Invoca Lambda 'initiator' (Factor Redondeo) â† REUTILIZA  â”‚
â”‚ 5. Actualiza DynamoDB IPP: status = 'factor_initiated'         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 4: Factor de Redondeo Procesa (EXISTENTE - Sin cambios)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. initiator genera processId y guarda en DynamoDB             â”‚
â”‚ 2. Inicia Step Function                                        â”‚
â”‚ 3. client-separator detecta 1 cliente (ya viene separado)      â”‚
â”‚ 4. processor aplica Factor de Redondeo:                        â”‚
â”‚    - Lee Excel del cliente                                     â”‚
â”‚    - Consulta ventas en Databricks                             â”‚
â”‚    - Calcula factor Ã³ptimo                                     â”‚
â”‚    - Aplica reglas de redondeo                                 â”‚
â”‚ 5. Guarda resultado en S3: results/resultados/{processId}/     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 5: Subir Resultados a Databricks Gold (FUTURO)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. factor-to-databricks lee consolidado.xlsx                   â”‚
â”‚ 2. Por cada cliente crea/actualiza tabla Gold:                 â”‚
â”‚    invenadro.gold.factor_redondeo_{mostrador}                  â”‚
â”‚ 3. Actualiza DynamoDB IPP: status = 'databricks_uploaded'      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—‚ï¸ Estructura de Archivos en S3

### **IPP Raw Bucket:**
```
s3://invenadro-backend-jul-dev-ipp-raw/
â””â”€â”€ resultados/
    â””â”€â”€ ipp_abc123/
        â”œâ”€â”€ metadata.json                    â† Dispara Lambda Bridge
        â””â”€â”€ clientes/
            â”œâ”€â”€ cliente_7051602.json         â† 5,000 registros
            â”œâ”€â”€ cliente_7051603.json         â† 5,000 registros
            â””â”€â”€ cliente_7051604.json         â† 5,000 registros
```

### **Uploads Bucket (Factor Redondeo Input):**
```
s3://invenadro-backend-jul-dev-uploads/
â””â”€â”€ ipp-to-factor/
    â””â”€â”€ ipp_abc123/
        â”œâ”€â”€ 7051602/
        â”‚   â””â”€â”€ input.xlsx                   â† Excel para Factor Redondeo
        â”œâ”€â”€ 7051603/
        â”‚   â””â”€â”€ input.xlsx
        â””â”€â”€ 7051604/
            â””â”€â”€ input.xlsx
```

### **Results Bucket (Factor Redondeo Output):**
```
s3://invenadro-backend-jul-dev-results/
â””â”€â”€ resultados/
    â”œâ”€â”€ uuid-111/
    â”‚   â””â”€â”€ resultado.json                   â† Resultado cliente 7051602
    â”œâ”€â”€ uuid-222/
    â”‚   â””â”€â”€ resultado.json                   â† Resultado cliente 7051603
    â””â”€â”€ uuid-333/
        â””â”€â”€ resultado.json                   â† Resultado cliente 7051604
```

---

## ğŸ”§ ConfiguraciÃ³n Necesaria

### **1. Databricks Secrets (Ya deberÃ­as tenerlos):**
```bash
databricks secrets create-scope --scope aws-creds
databricks secrets put --scope aws-creds --key access-key
databricks secrets put --scope aws-creds --key secret-key
```

### **2. Usuario IAM en AWS:**
Ya lo creaste antes con permisos para S3 y DynamoDB.

### **3. Notebook de Databricks:**
Copia el cÃ³digo de `DATABRICKS_NOTEBOOK_CODE.py` y agrÃ©galo a tu notebook:
- **Widgets**: Al inicio del notebook (primera cell)
- **Procesamiento IPP**: Tu cÃ³digo actual (medio)
- **Guardar en S3**: Al final del notebook (Ãºltima cell)

---

## ğŸš€ Deploy

### **1. Instalar dependencias nuevas:**
```bash
cd services/backend
npm install
```

### **2. Verificar cambios:**
```bash
# Ver funciones que se deployarÃ¡n
npx serverless info --stage jul-dev
```

### **3. Deploy completo:**
```bash
npx serverless deploy --stage jul-dev
```

O deploy solo de la nueva funciÃ³n:
```bash
npx serverless deploy function -f ippToFactorBridge --stage jul-dev
```

---

## ğŸ§ª Testing

### **Paso 1: Probar IPP completo desde Frontend**
```
1. Ir a frontend IPP
2. Ingresar mostradores: 7051602,7051603
3. Validar
4. Continuar
5. Esperar que Databricks Job 1 complete (~20 min)
```

### **Paso 2: Verificar archivos en S3**
```bash
# Ver que se crearon los archivos particionados
aws s3 ls s3://invenadro-backend-jul-dev-ipp-raw/resultados/ --recursive

# Ver metadata.json
aws s3 cp s3://invenadro-backend-jul-dev-ipp-raw/resultados/ipp_XXX/metadata.json - | jq .

# Ver archivo de un cliente
aws s3 cp s3://invenadro-backend-jul-dev-ipp-raw/resultados/ipp_XXX/clientes/cliente_7051602.json - | jq .
```

### **Paso 3: Verificar que Bridge se ejecutÃ³**
```bash
# Ver logs de la lambda bridge
npx serverless logs -f ippToFactorBridge --stage jul-dev --tail

# DeberÃ­as ver:
# âœ… Metadata leÃ­da
# âœ… [1/2] Procesando cliente: 7051602
# âœ… Excel generado
# âœ… Initiator invocado
# âœ… [2/2] Procesando cliente: 7051603
```

### **Paso 4: Verificar que Factor de Redondeo se ejecutÃ³**
```bash
# Ver logs del initiator (uno por cliente)
npx serverless logs -f initiator --stage jul-dev --tail

# Ver resultados en S3
aws s3 ls s3://invenadro-backend-jul-dev-results/resultados/ --recursive
```

---

## ğŸ“Š Monitoreo en DynamoDB

### **Tabla IPP Jobs:**
```bash
aws dynamodb get-item \
  --table-name invenadro-backend-jul-dev-ipp-jobs \
  --key '{"job_id":{"S":"ipp_abc123"}}'
```

**Estados esperados:**
```
job1_running      â†’ Databricks procesando
completed         â†’ Databricks terminÃ³, guardÃ³ en S3
factor_initiated  â†’ Bridge enviÃ³ clientes a Factor Redondeo
factor_completed  â†’ Todos los clientes procesados (futuro)
```

### **Tabla Jobs (Factor Redondeo):**
```bash
aws dynamodb scan \
  --table-name invenadro-backend-jul-dev-jobs \
  --filter-expression "contains(customConfig, :source)" \
  --expression-attribute-values '{":source":{"S":"IPP"}}'
```

---

## ğŸ› Troubleshooting

### **Problema: Bridge no se ejecuta**

**SÃ­ntoma:** Databricks completa pero Bridge no arranca.

**SoluciÃ³n:**
```bash
# 1. Verificar que metadata.json existe
aws s3 ls s3://invenadro-backend-jul-dev-ipp-raw/resultados/ipp_XXX/

# 2. Verificar permisos S3 Event Notification
aws s3api get-bucket-notification-configuration \
  --bucket invenadro-backend-jul-dev-ipp-raw

# 3. Invocar manualmente para testing
aws lambda invoke \
  --function-name invenadro-backend-jul-dev-ipp-to-factor-bridge \
  --payload file://test-event.json \
  response.json
```

### **Problema: TransformaciÃ³n JSON â†’ Excel falla**

**SÃ­ntoma:** Bridge ejecuta pero Excel estÃ¡ corrupto.

**SoluciÃ³n:**
```bash
# 1. Ver logs detallados
npx serverless logs -f ippToFactorBridge --stage jul-dev --startTime 10m

# 2. Verificar estructura del JSON cliente
aws s3 cp s3://invenadro-backend-jul-dev-ipp-raw/resultados/ipp_XXX/clientes/cliente_7051602.json - | jq '.datos[0]'

# Debe tener: MATERIAL_MG, Descripcion, Factor_4, Precio_Farmacia
```

### **Problema: Factor de Redondeo no procesa correctamente**

**SÃ­ntoma:** Initiator ejecuta pero processor falla.

**SoluciÃ³n:**
```bash
# 1. Descargar Excel generado y verificar
aws s3 cp s3://invenadro-backend-jul-dev-uploads/ipp-to-factor/ipp_XXX/7051602/input.xlsx .

# 2. Ver logs del processor
npx serverless logs -f processor --stage jul-dev --tail

# 3. Verificar que Excel tiene columnas correctas:
# - Cliente
# - Material
# - Descripcion
# - Inventario
# - Precio
```

---

## ğŸ“ˆ MÃ©tricas y Costos

### **EjecuciÃ³n tÃ­pica (100 clientes):**

| Lambda | DuraciÃ³n | Costo (aprox) |
|--------|----------|---------------|
| ipp-iniciador | 5s | $0.0001 |
| Databricks Job 1 | 20 min | Costo Databricks |
| ipp-to-factor-bridge | 2 min | $0.002 |
| initiator Ã— 100 | 5s Ã— 100 | $0.01 |
| processor Ã— 100 | 60s Ã— 100 | $0.10 |
| **TOTAL** | ~22 min | **~$0.12** + Databricks |

**S3 Requests:**
- PutObject: ~300 (metadata + clientes + excels)
- GetObject: ~400 (lectura bridge + processor)
- Costo: ~$0.0015

**DynamoDB:**
- Writes: ~205 (1 IPP + 4 por cliente)
- Reads: ~100 (status checks)
- Costo: ~$0.0003

---

## âš¡ Optimizaciones Futuras

### **1. Paralelizar Bridge (Si tienes 1000+ clientes):**
```javascript
// En lugar de procesar secuencialmente, usar Promise.all con batches
const BATCH_SIZE = 10;
for (let i = 0; i < clientes.length; i += BATCH_SIZE) {
  const batch = clientes.slice(i, i + BATCH_SIZE);
  await Promise.all(batch.map(cliente => procesarCliente(cliente)));
}
```

### **2. Usar SQS como Buffer:**
```
Bridge â†’ SQS Queue â†’ Lambda Consumer (procesa 1 cliente)
```
Ventajas: Mejor control de rate limiting, reintentos automÃ¡ticos.

### **3. Agregar CloudWatch Dashboard:**
Monitorear:
- Tiempo de ejecuciÃ³n Bridge
- Ã‰xito/Fallo por cliente
- Throughput (clientes/minuto)

---

## ğŸ“ PrÃ³ximos Pasos

1. âœ… Deploy de `ipp-to-factor-bridge`
2. âœ… Modificar Notebook Databricks (agregar cÃ³digo S3)
3. â³ Probar flujo completo end-to-end
4. â³ Crear `factor-to-databricks` (Fase 5)
5. â³ Integrar multi-cuenta (nadro-prod)

---

## ğŸ¯ Resumen

**Lo que hicimos:**
1. âœ… Creamos Lambda `ipp-to-factor-bridge`
2. âœ… Configuramos S3 Event Notification (automÃ¡tico)
3. âœ… Reutilizamos TODO el Factor de Redondeo existente
4. âœ… Particionamos por cliente para evitar problemas de memoria
5. âœ… Hicimos que cada cliente se procese independientemente

**Ventajas:**
- âœ… No modificamos nada del Factor de Redondeo
- âœ… Escalable (1 cliente o 1000 clientes)
- âœ… Resiliente (si falla 1 cliente, los demÃ¡s continÃºan)
- âœ… Trazable (logs por cada paso)
- âœ… Event-driven (sin polling innecesario)

---

Â¿Preguntas? Revisa el cÃ³digo en:
- `functionsIPP/ipp-to-factor-bridge/index.js`
- `DATABRICKS_NOTEBOOK_CODE.py`

